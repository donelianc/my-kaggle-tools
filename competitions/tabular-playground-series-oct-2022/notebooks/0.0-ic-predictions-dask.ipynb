{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Libraries and Personal Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import sys\n",
    "from os.path import abspath\n",
    "\n",
    "from multiprocessing import cpu_count\n",
    "from gc import collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "\n",
    "# Set the default figure size and theme to display good looking matplotlib plots.\n",
    "rcParams[\"figure.figsize\"] = (10, 6)\n",
    "plt.style.use(\"fivethirtyeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import set_option\n",
    "set_option(\"display.max_rows\", 200)\n",
    "set_option(\"display.max_columns\", 100)\n",
    "set_option(\"display.max_colwidth\", 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add absolute path from root to sys.path to use custom modules\n",
    "sys.path.insert(0, abspath('..'))\n",
    "\n",
    "from src.models.train_model import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.utils import create_kf_groups\n",
    "\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, GroupKFold\n",
    "\n",
    "from lightgbm import LGBMClassifier, log_evaluation, early_stopping\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.callbacks import DeadlineStopper, DeltaYStopper, CheckpointSaver\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_params = {\n",
    "    \"n_estimators\": 5000, \n",
    "    \"learning_rate\": 0.05, \n",
    "    \"max_bin\": 50,\n",
    "    \"num_leaves\": 1500,\n",
    "    \"max_depth\": 10,\n",
    "    \"min_child_weight\": 10,\n",
    "    \"reg_alpha\": 10.0,\n",
    "    \"reg_lambda\": 10.0,\n",
    "    # \"min_data_in_leaf\": int(groups.value_counts().mean().round(-4)*0.01),\n",
    "    \"min_gain_to_split\": 5,\n",
    "    \"max_bin\": 100,\n",
    "    \"subsample\": 0.7,\n",
    "    \"colsample_bytree\": 0.9,\n",
    "    # \"scale_pos_weight\": int(scale_pos_w),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_95476/417491221.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_cv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_cv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/ian.castillo_nfs/my-kaggle-tools/competitions/tabular-playground-series-oct-2022/.kaggle-main/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"passthrough\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ian.castillo_nfs/my-kaggle-tools/competitions/tabular-playground-series-oct-2022/.kaggle-main/lib/python3.7/site-packages/sklearn/decomposition/_incremental_pca.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0mX_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ian.castillo_nfs/my-kaggle-tools/competitions/tabular-playground-series-oct-2022/.kaggle-main/lib/python3.7/site-packages/sklearn/decomposition/_incremental_pca.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y, check_input)\u001b[0m\n\u001b[1;32m    333\u001b[0m             )\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_matrices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvd_flip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_based_decision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0mexplained_variance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mS\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_total_samples\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ian.castillo_nfs/my-kaggle-tools/competitions/tabular-playground-series-oct-2022/.kaggle-main/lib/python3.7/site-packages/scipy/linalg/decomp_svd.py\u001b[0m in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv, overwrite_a, check_finite, lapack_driver)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;31m# perform decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     u, s, v, info = gesXd(a1, compute_uv=compute_uv, lwork=lwork,\n\u001b[0;32m--> 128\u001b[0;31m                           full_matrices=full_matrices, overwrite_a=overwrite_a)\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "base_model = BaseModel()\n",
    "base_model.read_config(\"../models/config.yaml\")\n",
    "features, target = base_model.get_data()\n",
    "base_model.build_base_pipeline()\n",
    "\n",
    "\n",
    "gsp = GroupShuffleSplit(n_splits=2, test_size=0.20, random_state=777)\n",
    "train_index, test_index = next(gsp.split(base_model.data, groups=base_model.data.index.get_level_values(\"game_num\")))\n",
    "\n",
    "X_train = base_model.data[features + [target]].iloc[train_index]\n",
    "\n",
    "X_valid = base_model.data[features].iloc[test_index]\n",
    "y_valid = base_model.data[target].iloc[test_index]\n",
    "\n",
    "\n",
    "train_index, test_index = next(gsp.split(X_train, groups=X_train.index.get_level_values(\"game_num\")))\n",
    "\n",
    "X_train_cv = X_train[features].iloc[train_index]\n",
    "y_train_cv = X_train[target].iloc[train_index]\n",
    "\n",
    "X_test = X_train[features].iloc[test_index]\n",
    "y_test = X_train[target].iloc[test_index]\n",
    "\n",
    "\n",
    "n_folds = 5\n",
    "game_num = X_train_cv.index.get_level_values(\"game_num\")\n",
    "groups = create_kf_groups(game_num, n_folds=n_folds)\n",
    "gkf = GroupKFold(n_splits=n_folds)\n",
    "\n",
    "\n",
    "if base_model.config[\"model\"][\"ipca\"][\"batch_size\"] == \"auto\":\n",
    "    TOTAL_IPCA_BATCHES = 10\n",
    "    ipca_batch = int(round(groups.value_counts().mean() / TOTAL_IPCA_BATCHES, -3))\n",
    "else:\n",
    "    ipca_batch = base_model.config[\"model\"][\"ipca\"][\"batch_size\"]\n",
    "\n",
    "\n",
    "base_model.base_pipeline.steps.append((\n",
    "    \"ipca\", \n",
    "    IncrementalPCA(\n",
    "        n_components=base_model.config[\"model\"][\"ipca\"][\"n_components\"], \n",
    "        batch_size=ipca_batch,\n",
    "        whiten=base_model.config[\"model\"][\"ipca\"][\"whiten\"]\n",
    "        ),\n",
    "    ))\n",
    "\n",
    "\n",
    "base_model.base_pipeline.fit(X_train_cv, y_train_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_trans = base_model.base_pipeline.transform(X_train_cv)\n",
    "X_test_trans = base_model.base_pipeline.transform(X_test)\n",
    "X_valid_trans = base_model.base_pipeline.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dX_train_cv = dd.from_pandas(X_train_trans.reset_index(drop=True), npartitions=cpu_count()).persist()\n",
    "dy_train_cv = dd.from_pandas(y_train_cv.reset_index(drop=True), npartitions=cpu_count()).persist()\n",
    "\n",
    "dX_test = dd.from_pandas(X_test_trans.reset_index(drop=True), npartitions=cpu_count()).persist()\n",
    "dy_test = dd.from_pandas(y_test.reset_index(drop=True), npartitions=cpu_count()).persist()\n",
    "\n",
    "dX_valid = dd.from_pandas(X_valid_trans.reset_index(drop=True), npartitions=cpu_count()).persist()\n",
    "dy_valid = dd.from_pandas(y_valid.reset_index(drop=True), npartitions=cpu_count()).persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_pos_w = y_train_cv.value_counts().round(-4)\n",
    "scale_pos_w = scale_pos_w[0] / scale_pos_w[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = base_model.config[\"model\"][\"type\"]\n",
    "# base_model.base_pipeline.steps.append((model_type, best_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_params = {\n",
    "    f\"{model_type}__eval_set\": [(dX_test, dy_test)],\n",
    "    f\"{model_type}__eval_metric\": \"neg_log_loss\",\n",
    "    f\"{model_type}__callbacks\": [\n",
    "        early_stopping(int(best_model_params[\"n_estimators\"]*0.1)),\n",
    "        log_evaluation(period=100, show_stdv=True), \n",
    "    ],\n",
    "}\n",
    "\n",
    "fit_params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from distributed import Client, LocalCluster\n",
    "\n",
    "cluster = LocalCluster()\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask.config.set({\"array.chunk-size\": \"128 MiB\"})\n",
    "dask.config.set({\"distributed.workers.memory.spill\": 0.85})\n",
    "dask.config.set({\"distributed.workers.memory.target\": 0.75})\n",
    "dask.config.set({\"distributed.workers.memory.terminate\": 0.98})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_clf = lgb.DaskLGBMClassifier(\n",
    "    client=client, \n",
    "    objective=\"binary\", random_state=777, # n_jobs=cpu_count(),\n",
    "    boosting_type=\"goss\", n_estimators=1000, learning_rate=0.01, max_bin=25,\n",
    "    min_child_samples=None, min_split_gain=None\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = dask_clf.fit(X=dX_train_cv, y=dy_train_cv, **fit_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team = base_model.config[\"model\"][\"team\"]\n",
    "model = base_model.config[\"model\"][\"type\"]\n",
    "\n",
    "from joblib import dump\n",
    "dump(best_model, f\"../models/team{team}/{model}_latest/{model}_latest.joblib\")\n",
    "\n",
    "from json import dump, dumps\n",
    "with open(f\"../models/team{team}/{model}_latest/{model}_latest.json\", \"w\") as f:\n",
    "    dump(dumps(best_model_params, default=str), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = best_model.predict_proba(X_valid)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "log_loss(y_valid, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from pandas.core.frame import DataFrame, Series\n",
    "from pandas import concat\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "# Kudos to: Mateus Coelho\n",
    "# https://www.kaggle.com/code/mateuscco/how-to-evaluate-model-calibration/notebook\n",
    "\n",
    "def ece(y_test, preds, strategy = 'uniform'):\n",
    "    df = DataFrame({'target': y_test, 'proba': preds, 'bin': np.nan})\n",
    "    \n",
    "    if(strategy == 'uniform'):\n",
    "        lim_inf = np.linspace(0, 0.9, 10)\n",
    "        for idx, lim in enumerate(lim_inf):\n",
    "            df.loc[df['proba'] >= lim, 'bin'] = idx\n",
    "\n",
    "    elif(strategy == 'quantile'):\n",
    "        pass\n",
    "    \n",
    "    df_bin_groups = concat([df.groupby('bin').mean(), df['bin'].value_counts()], axis = 1)\n",
    "    df_bin_groups['ece'] = (df_bin_groups['target'] - df_bin_groups['proba']).abs() * (df_bin_groups['bin'] / df.shape[0])\n",
    "    return df_bin_groups['ece'].sum()\n",
    "\n",
    "def make_report(y_test, preds):\n",
    "    # Computing AUC\n",
    "    auc = roc_auc_score(y_test, preds)\n",
    "    display(f'AUROC: {auc}')\n",
    "    display(f'AUROC: {2*auc-1}')\n",
    "    display(f'Fraction of positive cases in the test set: {y_test.mean()}')\n",
    "    display(f'Mean predicted value in the test set:       {preds.mean()}')\n",
    "    display(f'ECE (equal width bins):       {ece(y_test, preds)}')\n",
    "    \n",
    "    # Plotting probabilities\n",
    "    display('#### Histogram of the probability distribution')\n",
    "    Series(preds).hist(bins = 40)\n",
    "    plt.show()\n",
    "    \n",
    "    # Plotting KDE by class\n",
    "    display('#### KDE plots of the probability distribution by class')\n",
    "    fig, ax1 = plt.subplots()\n",
    "    sns.kdeplot(preds[y_test == 0], label = 'No goal', ax = ax1)\n",
    "    ax2 = ax1.twinx()\n",
    "    sns.kdeplot(preds[y_test == 1], label = 'Goal within 10s', color = 'red', ax = ax2)\n",
    "    lines, labels = ax1.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    ax2.legend(lines + lines2, labels + labels2, loc=0)\n",
    "    plt.show()\n",
    "    \n",
    "    # Plotting calibration\n",
    "    display('#### Calibration curve (equal width bins)')\n",
    "    fop, mpv = calibration_curve(y_test, preds, n_bins=10)\n",
    "    plt.plot(mpv, fop, \"s-\", label='model')\n",
    "    plt.plot([0,0.25],[0,0.25], label='ideal')\n",
    "    plt.xlabel('Mean predicted value')\n",
    "    plt.ylabel('Fraction of positives')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    display('#### Calibration curve (equal size bins)')\n",
    "    fop, mpv = calibration_curve(y_test, preds, n_bins=10, strategy='quantile')\n",
    "    plt.plot(mpv, fop, \"s-\", label='model')\n",
    "    plt.plot([0,0.25],[0,0.25], label='ideal')\n",
    "    plt.xlabel('Mean predicted value')\n",
    "    plt.ylabel('Fraction of positives')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_report(y_valid, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.4 ('.kaggle-main': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e5c0cff39fa72bd2c44889eae792c2a5fab03a1c30a13a1587ff99bf2992359e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
