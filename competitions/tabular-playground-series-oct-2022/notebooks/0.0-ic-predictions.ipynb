{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Libraries and Personal Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from os.path import abspath\n",
    "\n",
    "from multiprocessing import cpu_count\n",
    "from gc import collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "\n",
    "# Set the default figure size and theme to display good looking matplotlib plots.\n",
    "rcParams[\"figure.figsize\"] = (10, 6)\n",
    "plt.style.use(\"fivethirtyeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import set_option\n",
    "set_option(\"display.max_rows\", 200)\n",
    "set_option(\"display.max_columns\", 100)\n",
    "set_option(\"display.max_colwidth\", 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add absolute path from root to sys.path to use custom modules\n",
    "sys.path.insert(0, abspath('..'))\n",
    "\n",
    "from src.models.train_model import BaseModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Build Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = BaseModel()\n",
    "base_model.read_config(\"../models/config.yaml\")\n",
    "features, target = base_model.get_data()\n",
    "base_model.build_base_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model.base_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pandas.core.frame import DataFrame\n",
    "# DataFrame(base_model.base_pipeline.fit_transform(base_model.data)).isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Parameter Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.utils import create_kf_groups\n",
    "\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, GroupKFold\n",
    "\n",
    "from lightgbm import LGBMClassifier, log_evaluation, early_stopping\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.callbacks import DeadlineStopper, DeltaYStopper, CheckpointSaver\n",
    "from skopt.space import Real, Categorical, Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "gsp = GroupShuffleSplit(n_splits=2, test_size=0.20, random_state=777)\n",
    "train_index, test_index = next(gsp.split(base_model.data, groups=base_model.data.index.get_level_values(\"game_num\")))\n",
    "\n",
    "X_train = base_model.data[features + [target]].iloc[train_index]\n",
    "\n",
    "X_valid = base_model.data[features].iloc[test_index]\n",
    "y_valid = base_model.data[target].iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index, test_index = next(gsp.split(X_train, groups=X_train.index.get_level_values(\"game_num\")))\n",
    "\n",
    "X_train_cv = X_train[features].iloc[train_index]\n",
    "y_train_cv = X_train[target].iloc[train_index]\n",
    "\n",
    "X_test = X_train[features].iloc[test_index]\n",
    "y_test = X_train[target].iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_cv.shape: (3396870, 54)\n",
      "X_test.shape: (845350, 54)\n",
      "X_valid.shape: (1057376, 54)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train_cv.shape: {X_train_cv.shape}\")\n",
    "print(f\"X_test.shape: {X_test.shape}\")\n",
    "print(f\"X_valid.shape: {X_valid.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['preprocessor'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.base_pipeline.named_steps.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pandas.core.frame import DataFrame\n",
    "# DataFrame(base_model.base_pipeline.fit_transform(X_train_cv)).describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_pos_w = y_train_cv.value_counts().round(-4)\n",
    "scale_pos_w = scale_pos_w[0] / scale_pos_w[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    689194\n",
       "b    682622\n",
       "c    673678\n",
       "d    669740\n",
       "e    681636\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_folds = 5\n",
    "game_num = X_train_cv.index.get_level_values(\"game_num\")\n",
    "groups = create_kf_groups(game_num, n_folds=n_folds)\n",
    "gkf = GroupKFold(n_splits=n_folds)\n",
    "groups.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if base_model.config[\"model\"][\"ipca\"][\"batch_size\"] == \"auto\":\n",
    "    TOTAL_IPCA_BATCHES = 10\n",
    "    ipca_batch = int(round(groups.value_counts().mean() / TOTAL_IPCA_BATCHES, -3))\n",
    "else:\n",
    "    ipca_batch = base_model.config[\"model\"][\"ipca\"][\"batch_size\"]\n",
    "ipca_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 FeatureUnion(transformer_list=[('player',\n",
       "                                                 ColumnTransformer(transformers=[('demolished',\n",
       "                                                                                  PlayerDemolished(),\n",
       "                                                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7f908c8c72d0>),\n",
       "                                                                                 ('position',\n",
       "                                                                                  Pipeline(steps=[('imputer',\n",
       "                                                                                                   SimpleImputer(fill_value=0.0,\n",
       "                                                                                                                 strategy='constant')),\n",
       "                                                                                                  ('scaler',\n",
       "                                                                                                   StandardScaler())]),\n",
       "                                                                                  <sklearn.c...\n",
       "                                                                                                                 strategy='constant')),\n",
       "                                                                                                  ('scaler',\n",
       "                                                                                                   MaxAbsScaler())]),\n",
       "                                                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7f908f1422d0>)])),\n",
       "                                                ('team',\n",
       "                                                 ColumnTransformer(transformers=[('centroid',\n",
       "                                                                                  Pipeline(steps=[('team_centroid',\n",
       "                                                                                                   TeamCentroid()),\n",
       "                                                                                                  ('scaler',\n",
       "                                                                                                   StandardScaler())]),\n",
       "                                                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7f908f2310d0>)]))]))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.base_pipeline.fit(X_train_cv, y_train_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_trans = base_model.base_pipeline.transform(X_train_cv)\n",
    "X_test_trans = base_model.base_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train with All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_params = {\n",
    "    \"n_estimators\": 5000, \n",
    "    \"learning_rate\": 0.05, \n",
    "    \"max_bin\": 50,\n",
    "    \"num_leaves\": 1500,\n",
    "    \"max_depth\": 10,\n",
    "    \"min_child_weight\": 10,\n",
    "    \"reg_alpha\": 10.0,\n",
    "    \"reg_lambda\": 10.0,\n",
    "    \"min_data_in_leaf\": int(groups.value_counts().mean().round(-4)*0.01),\n",
    "    \"min_gain_to_split\": 5,\n",
    "    \"max_bin\": 100,\n",
    "    \"subsample\": 0.7,\n",
    "    \"colsample_bytree\": 0.9,\n",
    "    \"scale_pos_weight\": int(scale_pos_w),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = BaseModel()\n",
    "base_model.read_config(\"../models/config.yaml\")\n",
    "features, target = base_model.get_data()\n",
    "base_model.build_base_pipeline()\n",
    "\n",
    "if base_model.config[\"model\"][\"type\"] == \"xgb\":\n",
    "    best_model = XGBClassifier(**best_model_params, random_state=777)\n",
    "elif base_model.config[\"model\"][\"type\"] == \"lgbm\":\n",
    "    best_model = LGBMClassifier(\n",
    "        **best_model_params, \n",
    "        boosting_type=\"goss\",\n",
    "        objective=\"binary\",\n",
    "        min_child_samples=None, \n",
    "        min_split_gain=None,\n",
    "        random_state=777, \n",
    "        n_jobs=cpu_count()\n",
    "        )\n",
    "\n",
    "base_model.base_pipeline.steps.append((\n",
    "    \"ipca\", \n",
    "    IncrementalPCA(\n",
    "        n_components=base_model.config[\"model\"][\"ipca\"][\"n_components\"], \n",
    "        batch_size=ipca_batch,\n",
    "        whiten=base_model.config[\"model\"][\"ipca\"][\"whiten\"]\n",
    "        ),\n",
    "    ))\n",
    "\n",
    "X_test_trans = base_model.base_pipeline.fit_transform(X_test)\n",
    "\n",
    "model_type = base_model.config[\"model\"][\"type\"]\n",
    "base_model.base_pipeline.steps.append((model_type, best_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['lgbm__eval_set', 'lgbm__eval_metric', 'lgbm__callbacks'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_params = {\n",
    "    f\"{model_type}__eval_set\": [(X_test_trans, y_test)],\n",
    "    f\"{model_type}__eval_metric\": \"neg_log_loss\",\n",
    "    f\"{model_type}__callbacks\": [\n",
    "        early_stopping(int(best_model_params[\"n_estimators\"]*0.1)),\n",
    "        log_evaluation(period=100, show_stdv=True), \n",
    "    ],\n",
    "}\n",
    "\n",
    "fit_params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.654103\n",
      "[200]\tvalid_0's binary_logloss: 0.657935\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_88169/3587977636.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"lgbm\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     best_model = base_model.base_pipeline.fit(\n\u001b[0;32m----> 6\u001b[0;31m         X=X_train_cv, y=y_train_cv, **fit_params)\n\u001b[0m",
      "\u001b[0;32m~/ian.castillo_nfs/my-kaggle-tools/competitions/tabular-playground-series-oct-2022/.kaggle-main/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"passthrough\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ian.castillo_nfs/my-kaggle-tools/competitions/tabular-playground-series-oct-2022/.kaggle-main/lib/python3.7/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    970\u001b[0m                     \u001b[0meval_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_metric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m                     callbacks=callbacks, init_model=init_model)\n\u001b[0m\u001b[1;32m    973\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ian.castillo_nfs/my-kaggle-tools/competitions/tabular-playground-series-oct-2022/.kaggle-main/lib/python3.7/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0minit_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m         )\n\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ian.castillo_nfs/my-kaggle-tools/competitions/tabular-playground-series-oct-2022/.kaggle-main/lib/python3.7/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    290\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ian.castillo_nfs/my-kaggle-tools/competitions/tabular-playground-series-oct-2022/.kaggle-main/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   3021\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   3022\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3023\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   3024\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3025\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if base_model.config[\"model\"][\"type\"] == \"xgb\":\n",
    "    best_model = base_model.base_pipeline.fit(X_train_cv, y_train_cv)\n",
    "\n",
    "elif base_model.config[\"model\"][\"type\"] == \"lgbm\":\n",
    "    best_model = base_model.base_pipeline.fit(\n",
    "        X=X_train_cv, y=y_train_cv, **fit_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team = base_model.config[\"model\"][\"team\"]\n",
    "model = base_model.config[\"model\"][\"type\"]\n",
    "\n",
    "from joblib import dump\n",
    "dump(best_model, f\"../models/team{team}/{model}_latest/{model}_latest.joblib\")\n",
    "\n",
    "from json import dump, dumps\n",
    "with open(f\"../models/team{team}/{model}_latest/{model}_latest.json\", \"w\") as f:\n",
    "    dump(dumps(best_model_params, default=str), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = best_model.predict_proba(X_valid)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "log_loss(y_valid, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from pandas.core.frame import DataFrame, Series\n",
    "from pandas import concat\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "# Kudos to: Mateus Coelho\n",
    "# https://www.kaggle.com/code/mateuscco/how-to-evaluate-model-calibration/notebook\n",
    "\n",
    "def ece(y_test, preds, strategy = 'uniform'):\n",
    "    df = DataFrame({'target': y_test, 'proba': preds, 'bin': np.nan})\n",
    "    \n",
    "    if(strategy == 'uniform'):\n",
    "        lim_inf = np.linspace(0, 0.9, 10)\n",
    "        for idx, lim in enumerate(lim_inf):\n",
    "            df.loc[df['proba'] >= lim, 'bin'] = idx\n",
    "\n",
    "    elif(strategy == 'quantile'):\n",
    "        pass\n",
    "    \n",
    "    df_bin_groups = concat([df.groupby('bin').mean(), df['bin'].value_counts()], axis = 1)\n",
    "    df_bin_groups['ece'] = (df_bin_groups['target'] - df_bin_groups['proba']).abs() * (df_bin_groups['bin'] / df.shape[0])\n",
    "    return df_bin_groups['ece'].sum()\n",
    "\n",
    "def make_report(y_test, preds):\n",
    "    # Computing AUC\n",
    "    auc = roc_auc_score(y_test, preds)\n",
    "    display(f'AUROC: {auc}')\n",
    "    display(f'AUROC: {2*auc-1}')\n",
    "    display(f'Fraction of positive cases in the test set: {y_test.mean()}')\n",
    "    display(f'Mean predicted value in the test set:       {preds.mean()}')\n",
    "    display(f'ECE (equal width bins):       {ece(y_test, preds)}')\n",
    "    \n",
    "    # Plotting probabilities\n",
    "    display('#### Histogram of the probability distribution')\n",
    "    Series(preds).hist(bins = 40)\n",
    "    plt.show()\n",
    "    \n",
    "    # Plotting KDE by class\n",
    "    display('#### KDE plots of the probability distribution by class')\n",
    "    fig, ax1 = plt.subplots()\n",
    "    sns.kdeplot(preds[y_test == 0], label = 'No goal', ax = ax1)\n",
    "    ax2 = ax1.twinx()\n",
    "    sns.kdeplot(preds[y_test == 1], label = 'Goal within 10s', color = 'red', ax = ax2)\n",
    "    lines, labels = ax1.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    ax2.legend(lines + lines2, labels + labels2, loc=0)\n",
    "    plt.show()\n",
    "    \n",
    "    # Plotting calibration\n",
    "    display('#### Calibration curve (equal width bins)')\n",
    "    fop, mpv = calibration_curve(y_test, preds, n_bins=10)\n",
    "    plt.plot(mpv, fop, \"s-\", label='model')\n",
    "    plt.plot([0,0.25],[0,0.25], label='ideal')\n",
    "    plt.xlabel('Mean predicted value')\n",
    "    plt.ylabel('Fraction of positives')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    display('#### Calibration curve (equal size bins)')\n",
    "    fop, mpv = calibration_curve(y_test, preds, n_bins=10, strategy='quantile')\n",
    "    plt.plot(mpv, fop, \"s-\", label='model')\n",
    "    plt.plot([0,0.25],[0,0.25], label='ideal')\n",
    "    plt.xlabel('Mean predicted value')\n",
    "    plt.ylabel('Fraction of positives')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_report(y_valid, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.4 ('.kaggle-main': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e5c0cff39fa72bd2c44889eae792c2a5fab03a1c30a13a1587ff99bf2992359e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
