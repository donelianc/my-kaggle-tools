{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "\n",
    "from os.path import abspath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add absolute path from root to sys.path to use custom modules\n",
    "sys.path.insert(0, abspath('..'))\n",
    "\n",
    "# Check if the path is already added to sys.path\n",
    "[p for p in sys.path if p.endswith(\"2022\")]\n",
    "\n",
    "# Import custom modules\n",
    "from src.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Author: Ayush Bihani\n",
    "# Source: https://www.kaggle.com/code/hsuyab/fast-loading-high-compression-with-feather/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = []\n",
    "for dirname, _, filenames in os.walk(\"../data/raw\"):\n",
    "    for filename in filenames:\n",
    "        file_names.append(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths = []\n",
    "for k in file_names:\n",
    "    if 'train_' in k and 'dtypes' not in k:\n",
    "        train_paths.append(k)\n",
    "        \n",
    "train_paths.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test = pd.read_csv(train_paths[0])\n",
    "# df_test = reduce_mem_usage(df_test)\n",
    "# \n",
    "# df_test.head()\n",
    "# df_test.game_num.nunique()\n",
    "# df_test.groupby([\"game_num\", \"event_id\"])[[\"event_time\"]].count() # .describe()\n",
    "# df_test[(df_test.game_num == 1) & (df_test.event_id == 1002)].event_time.abs().round(-1).value_counts().sort_index()\n",
    "# \n",
    "# df_sampled = df_test.groupby([\"game_num\", \"event_id\"], group_keys=False).apply(lambda x: x.sample(frac=0.1))\n",
    "# df_sampled.groupby([\"game_num\", \"event_id\"])[[\"event_time\"]].count()\n",
    "# df_sampled[(df_sampled.game_num == 1) & (df_sampled.event_id == 1002)].event_time.abs().round(-1).value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The directory, ../data/interim/feather_data, has been created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 10.01 MB\n",
      "Memory usage after optimization is: 2.46 MB\n",
      "Decreased by 75.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:34<02:18, 17.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 10.11 MB\n",
      "Memory usage after optimization is: 2.49 MB\n",
      "Decreased by 75.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:51<02:00, 17.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 9.89 MB\n",
      "Memory usage after optimization is: 2.43 MB\n",
      "Decreased by 75.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [01:08<01:41, 16.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 9.83 MB\n",
      "Memory usage after optimization is: 2.42 MB\n",
      "Decreased by 75.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [01:25<01:24, 16.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 9.86 MB\n",
      "Memory usage after optimization is: 2.43 MB\n",
      "Decreased by 75.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [01:41<01:06, 16.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 9.75 MB\n",
      "Memory usage after optimization is: 2.40 MB\n",
      "Decreased by 75.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [01:57<00:49, 16.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 9.61 MB\n",
      "Memory usage after optimization is: 2.36 MB\n",
      "Decreased by 75.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [02:14<00:33, 16.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 9.82 MB\n",
      "Memory usage after optimization is: 2.42 MB\n",
      "Decreased by 75.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [02:31<00:16, 16.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 10.02 MB\n",
      "Memory usage after optimization is: 2.46 MB\n",
      "Decreased by 75.4%\n",
      "Memory usage of dataframe is 9.80 MB\n",
      "Memory usage after optimization is: 2.41 MB\n",
      "Decreased by 75.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:48<00:00, 16.85s/it]\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_FRAC = 0.01\n",
    "SEED = 777\n",
    "if not makedir_check(\"../data/interim/feather_data\"):\n",
    "\n",
    "    time_read = {}\n",
    "    size_file = {}\n",
    "    \n",
    "    for file_path in tqdm(train_paths):\n",
    "        \n",
    "        # ext can be feather\n",
    "        times = {}\n",
    "        sizes = {}\n",
    "        \n",
    "        # stores name of file to be saved as \n",
    "        name_files_ftr =  (\n",
    "            file_path.split(\"/\")[-1]\n",
    "            .replace(\".\", \"_compressed.\")\n",
    "            .replace(\"csv\",\"ftr\")\n",
    "        )\n",
    "        \n",
    "        # store only file name without extension\n",
    "        file_only = name_files_ftr.split(\"_c\")[0]\n",
    "\n",
    "        #read file csv\n",
    "        t1 = time()\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        if SAMPLE_FRAC < 1:\n",
    "            df = (\n",
    "                df\n",
    "                .groupby([\"game_num\", \"event_id\"], group_keys=False)\n",
    "                .apply(lambda x: x.sample(frac=SAMPLE_FRAC, random_state=SEED))\n",
    "                .reset_index(drop=True)\n",
    "                )\n",
    "\n",
    "        sizes[\"memory_csv\"] = df.memory_usage(deep=True).sum()/(1024**2)\n",
    "        times[\"read_csv\"] = time() - t1\n",
    "        df = reduce_mem_usage(df)\n",
    "        \n",
    "        # save to feather\n",
    "        df.to_feather(\"../data/interim/feather_data/\"+name_files_ftr)\n",
    "        \n",
    "        # calculate reading time for feather\n",
    "        t1 = time()\n",
    "        df = pd.read_feather(\"../data/interim/feather_data/\"+name_files_ftr)\n",
    "        sizes[\"memory_feather\"] = df.memory_usage(deep=True).sum()/(1024**2)\n",
    "        times[\"read_feather\"] = time() - t1\n",
    "        \n",
    "        # store size and time for a particular file\n",
    "        time_read[file_only] = times\n",
    "        size_file[file_only] = sizes\n",
    "\n",
    "\n",
    "    time_taken_read = pd.DataFrame(time_read).T\n",
    "    # rounding of time to 3 decimal places\n",
    "    time_taken_read = time_taken_read.apply(lambda x: x.round(3))\n",
    "    time_taken_read.columns = ['time_to_read_csv(seconds)', 'time_to_read_feather(seconds)']\n",
    "\n",
    "\n",
    "    size_of_files = pd.DataFrame(size_file).T\n",
    "    size_of_files = size_of_files.apply(lambda x: x.round(2))\n",
    "    size_of_files.columns = ['memory_csv(MB)', 'memory_feather(MB)']\n",
    "    size_of_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes_df = pd.read_csv(\"../data/raw/train_dtypes.csv\")\n",
    "dtypes = {k: v for (k, v) in zip(dtypes_df.column, dtypes_df.dtype)}\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for i in range(len(train_paths)):\n",
    "    df_aux = pd.read_feather(f\"../data/interim/feather_data/train_{i}_compressed.ftr\")\n",
    "    df_aux = df_aux.astype(dtypes)\n",
    "    df = pd.concat([df, df_aux])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 45.11 MB\n",
      "Memory usage after optimization is: 25.89 MB\n",
      "Decreased by 42.6%\n"
     ]
    }
   ],
   "source": [
    "df = reduce_mem_usage(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True).to_feather(f\"../data/interim/sample_{round(SAMPLE_FRAC*100)}perc_train_compressed.ftr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.4 ('.kaggle-main': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e5c0cff39fa72bd2c44889eae792c2a5fab03a1c30a13a1587ff99bf2992359e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
