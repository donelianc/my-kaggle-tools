{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Libraries and Personal Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from os.path import abspath\n",
    "\n",
    "from multiprocessing import cpu_count\n",
    "from gc import collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "\n",
    "# Set the default figure size and theme to display good looking matplotlib plots.\n",
    "rcParams[\"figure.figsize\"] = (10, 6)\n",
    "plt.style.use(\"fivethirtyeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import set_option\n",
    "set_option(\"display.max_rows\", 200)\n",
    "set_option(\"display.max_columns\", 100)\n",
    "set_option(\"display.max_colwidth\", 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add absolute path from root to sys.path to use custom modules\n",
    "sys.path.insert(0, abspath('..'))\n",
    "\n",
    "from src.models.train_model import BaseModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Build Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = BaseModel()\n",
    "base_model.read_config(\"../models/config.yaml\")\n",
    "features, target = base_model.get_data()\n",
    "base_model.build_base_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model.base_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pandas.core.frame import DataFrame\n",
    "# DataFrame(base_model.base_pipeline.fit_transform(base_model.data)).isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Parameter Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.utils import create_kf_groups\n",
    "\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, GroupKFold\n",
    "\n",
    "from lightgbm import LGBMClassifier, log_evaluation, early_stopping\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.callbacks import DeadlineStopper, DeltaYStopper, CheckpointSaver\n",
    "from skopt.space import Real, Categorical, Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "gsp = GroupShuffleSplit(n_splits=2, test_size=0.20, random_state=777)\n",
    "train_index, test_index = next(gsp.split(base_model.data, groups=base_model.data.index.get_level_values(\"game_num\")))\n",
    "\n",
    "X_train = base_model.data[features + [target]].iloc[train_index]\n",
    "\n",
    "X_valid = base_model.data[features].iloc[test_index]\n",
    "y_valid = base_model.data[target].iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index, test_index = next(gsp.split(X_train, groups=X_train.index.get_level_values(\"game_num\")))\n",
    "\n",
    "X_train_cv = X_train[features].iloc[train_index]\n",
    "y_train_cv = X_train[target].iloc[train_index]\n",
    "\n",
    "X_test = X_train[features].iloc[test_index]\n",
    "y_test = X_train[target].iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_cv.shape: (135831, 54)\n",
      "X_test.shape: (34082, 54)\n",
      "X_valid.shape: (42183, 54)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train_cv.shape: {X_train_cv.shape}\")\n",
    "print(f\"X_test.shape: {X_test.shape}\")\n",
    "print(f\"X_valid.shape: {X_valid.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['preprocessor'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.base_pipeline.named_steps.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pandas.core.frame import DataFrame\n",
    "# DataFrame(base_model.base_pipeline.fit_transform(X_train_cv)).describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_pos_w = y_train_cv.value_counts().round(-4)\n",
    "scale_pos_w = scale_pos_w[0] / scale_pos_w[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 FeatureUnion(transformer_list=[('player',\n",
       "                                                 ColumnTransformer(transformers=[('demolished',\n",
       "                                                                                  PlayerDemolished(),\n",
       "                                                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7f6ba40e9090>),\n",
       "                                                                                 ('position',\n",
       "                                                                                  Pipeline(steps=[('imputer',\n",
       "                                                                                                   SimpleImputer(fill_value=0.0,\n",
       "                                                                                                                 strategy='constant')),\n",
       "                                                                                                  ('scaler',\n",
       "                                                                                                   StandardScaler())]),\n",
       "                                                                                  <sklearn.c...\n",
       "                                                                                                                 strategy='constant')),\n",
       "                                                                                                  ('scaler',\n",
       "                                                                                                   MaxAbsScaler())]),\n",
       "                                                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7f6ba4b6e8d0>)])),\n",
       "                                                ('team',\n",
       "                                                 ColumnTransformer(transformers=[('centroid',\n",
       "                                                                                  Pipeline(steps=[('team_centroid',\n",
       "                                                                                                   TeamCentroid()),\n",
       "                                                                                                  ('scaler',\n",
       "                                                                                                   StandardScaler())]),\n",
       "                                                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7f6ba4b6e610>)]))]))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.base_pipeline.fit(X_train_cv, y_train_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_trans = base_model.base_pipeline.transform(X_train_cv)\n",
    "X_test_trans = base_model.base_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Define K-Group-Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "\n",
    "game_num = X_train_cv.index.get_level_values(\"game_num\")\n",
    "groups = create_kf_groups(game_num, n_folds=n_folds)\n",
    "\n",
    "gkf = GroupKFold(n_splits=n_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    27711\n",
       "b    27444\n",
       "c    26380\n",
       "d    27236\n",
       "e    27060\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if base_model.config[\"model\"][\"ipca\"][\"batch_size\"] == \"auto\":\n",
    "    TOTAL_IPCA_BATCHES = 50\n",
    "    ipca_batch = int(round(groups.value_counts().mean() / TOTAL_IPCA_BATCHES, -3))\n",
    "else:\n",
    "    ipca_batch = base_model.config[\"model\"][\"ipca\"][\"batch_size\"]\n",
    "ipca_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.base_pipeline.steps.append((\n",
    "    \"ipca\", \n",
    "    IncrementalPCA(\n",
    "        n_components=base_model.config[\"model\"][\"ipca\"][\"n_components\"], \n",
    "        batch_size=ipca_batch,\n",
    "        whiten=base_model.config[\"model\"][\"ipca\"][\"whiten\"]\n",
    "        ),\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if base_model.config[\"model\"][\"type\"] == \"xgb\":\n",
    "    clf = XGBClassifier(objective=\"binary:logistic\", random_state=777)\n",
    "    search_spaces = {\n",
    "            \"xgb__n_estimators\": Integer(200, 400),\n",
    "            \"xgb__learning_rate\": Real(0.05, 0.15, \"uniform\"),\n",
    "            \"xgb__max_depth\": Integer(4, 6),\n",
    "            \"xgb__gamma\": Real(0.05, 0.10, \"uniform\"),\n",
    "            \"xgb__subsample\": Real(0.6, 0.8, \"uniform\"),\n",
    "            \"xgb__colsample_bytree\": Real(0.8, 1.0, \"uniform\"),\n",
    "        }\n",
    "\n",
    "elif base_model.config[\"model\"][\"type\"] == \"lgbm\":\n",
    "    clf = LGBMClassifier(\n",
    "        objective=\"binary\", random_state=777, n_jobs=cpu_count(),\n",
    "        boosting_type=\"goss\", n_estimators=5000, learning_rate=0.05, max_bin=50,\n",
    "        min_child_samples=None, min_split_gain=None\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.base_pipeline.steps.append((base_model.config[\"model\"][\"type\"], clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['preprocessor', 'ipca', 'lgbm'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.base_pipeline.named_steps.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "430"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Hyperparameters - Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt.space import Integer, Categorical, Real\n",
    "from skopt.utils import use_named_args\n",
    "from skopt import gp_minimize\n",
    "from numpy import mean as np_mean\n",
    "\n",
    "# -----------------------------------------------------------------------------------\n",
    "#                   Guide on which params to tune/ NOT to tune\n",
    "#           source: https://github.com/Microsoft/LightGBM/issues/695\n",
    "# -----------------------------------------------------------------------------------\n",
    "# \n",
    "# For heavily unbalanced datasets such as 1:10000:\n",
    "# \n",
    "# - max_bin: keep it only for memory pressure, not to tune (otherwise overfitting)\n",
    "# - learning rate: keep it only for training speed, not to tune (otherwise overfitting)\n",
    "# - n_estimators: must be infinite and use early stopping to auto-tune (otherwise overfitting)\n",
    "# - num_leaves: [7, 4095]\n",
    "# - max_depth: [2, 63] and infinite \n",
    "# - scale_pos_weight: [1, 10000] \n",
    "# - min_child_weight: [0.01, (sample size / 1000)] \n",
    "# - subsample: [0.4, 1]\n",
    "# - bagging_fraction: only 1, keep as is (otherwise overfitting)\n",
    "# - colsample_bytree: [0.4, 1]\n",
    "# \n",
    "# Never tune following parameters unless you have an explicit requirement to tune them:\n",
    "#\n",
    "# - Learning rate (lower means longer to train but more accurate, higher means smaller to train but less accurate)\n",
    "# - Number of boosting iterations (automatically tuned with early stopping and learning rate)\n",
    "# - Maximum number of bins (RAM dependent)\n",
    "\n",
    "# Also: https://towardsdatascience.com/kagglers-guide-to-lightgbm-hyperparameter-tuning-with-optuna-in-2021-ed048d9838b5\n",
    "# And: https://neptune.ai/blog/lightgbm-parameters-guide\n",
    "# Finally: https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html#deal-with-over-fitting\n",
    "# About optimization: https://medium.com/sitechassethealthcenter/gaussian-process-to-optimize-hyperparameters-of-an-algorithm-5b4810277527\n",
    "\n",
    "# set up hyperparameter space\n",
    "space = [\n",
    "    \n",
    "    # boosting iterations\n",
    "    # TODO: 10000 when training with all data\n",
    "    # Integer(100, 550, name=\"n_estimators\"),\n",
    "    # Real(0.10, 0.15, name=\"learning_rate\"), # it is recommended to use smaller learning_rate with larger num_iterations.\n",
    "    \n",
    "    # model complexity\n",
    "    Integer(20, 3500, name=\"num_leaves\"), # keep it relatively small to avoid overfitting\n",
    "    Integer(5, 15, name=\"max_depth\"),\n",
    "    Real(5, 20, name=\"min_child_weight\"),\n",
    "    \n",
    "    # penalization to reduce overfitting\n",
    "    Real(0.0, 20.0, name=\"reg_alpha\"),\n",
    "    Real(0.0, 20.0, name=\"reg_lambda\"),\n",
    "    \n",
    "    # model regularization\n",
    "    Integer(int(groups.value_counts().mean().round(-4)*0.01), int(groups.value_counts().mean().round(-4)*0.05), name=\"min_data_in_leaf\"),\n",
    "    Real(0.05, 10, name=\"min_gain_to_split\"),\n",
    "    \n",
    "    # model train speed\n",
    "    # Real(15, 250, name=\"max_bin\"),\n",
    "    Real(0.25, 0.85, name=\"subsample\"),\n",
    "    Real(0.25, 1.0, name=\"colsample_bytree\"),\n",
    "    \n",
    "    # target class unbalance\n",
    "    Real(int(scale_pos_w)-5, int(scale_pos_w)+5, name=\"scale_pos_weight\"),\n",
    "    ]\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from typing import Callable\n",
    "\n",
    "@use_named_args(space)\n",
    "def objective(**params):\n",
    "    base_model.base_pipeline[\"lgbm\"].set_params(**params)\n",
    "    return -np_mean(\n",
    "        cross_val_score(\n",
    "            base_model.base_pipeline[\"lgbm\"], X_train_trans, y_train_cv, \n",
    "            cv=GroupKFold(n_splits=n_folds).split(X_train_cv, y_train_cv, groups=groups), \n",
    "            n_jobs=cpu_count(),\n",
    "            verbose=1,\n",
    "            scoring=\"neg_log_loss\", \n",
    "            fit_params={\n",
    "                \"eval_set\": [(X_test_trans, y_test)],\n",
    "                \"eval_metric\": \"binary_logloss\",\n",
    "                \"callbacks\": [\n",
    "                    early_stopping(50),\n",
    "                    log_evaluation(period=25, show_stdv=True), # the rule of thumb is to have it at 10% of your num_estimators\n",
    "                    ],\n",
    "            }\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at random point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=48)]: Using backend LokyBackend with 48 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\tvalid_0's binary_logloss: 0.38819\n",
      "[25]\tvalid_0's binary_logloss: 0.388498\n",
      "[25]\tvalid_0's binary_logloss: 0.387551\n",
      "[25]\tvalid_0's binary_logloss: 0.388714\n",
      "[25]\tvalid_0's binary_logloss: 0.389352\n",
      "[50]\tvalid_0's binary_logloss: 0.465187\n",
      "[50]\tvalid_0's binary_logloss: 0.464799\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.231626\n",
      "[50]\tvalid_0's binary_logloss: 0.465569\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.231422\n",
      "[50]\tvalid_0's binary_logloss: 0.466461\n",
      "[50]\tvalid_0's binary_logloss: 0.463681\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.231669\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.231571\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.231252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=48)]: Done   5 out of   5 | elapsed: 12.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 746.7118\n",
      "Function value obtained: 0.2275\n",
      "Current minimum: 0.2275\n",
      "Iteration No: 2 started. Evaluating function at random point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=48)]: Using backend LokyBackend with 48 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\tvalid_0's binary_logloss: 0.462031\n",
      "[25]\tvalid_0's binary_logloss: 0.461493\n",
      "[25]\tvalid_0's binary_logloss: 0.458494\n",
      "[25]\tvalid_0's binary_logloss: 0.460305\n",
      "[25]\tvalid_0's binary_logloss: 0.459243\n",
      "[50]\tvalid_0's binary_logloss: 0.567623\n",
      "[50]\tvalid_0's binary_logloss: 0.567465\n",
      "[50]\tvalid_0's binary_logloss: 0.563847\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.234098\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.234\n",
      "[50]\tvalid_0's binary_logloss: 0.56617\n",
      "[50]\tvalid_0's binary_logloss: 0.56429\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.233761\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.234042\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.233933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=48)]: Done   5 out of   5 | elapsed: 13.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 785.8021\n",
      "Function value obtained: 0.2301\n",
      "Current minimum: 0.2275\n",
      "Iteration No: 3 started. Evaluating function at random point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=48)]: Using backend LokyBackend with 48 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\tvalid_0's binary_logloss: 0.332127\n",
      "[25]\tvalid_0's binary_logloss: 0.331345\n",
      "[25]\tvalid_0's binary_logloss: 0.331387\n",
      "[25]\tvalid_0's binary_logloss: 0.330632\n",
      "[25]\tvalid_0's binary_logloss: 0.33248\n",
      "[50]\tvalid_0's binary_logloss: 0.382877\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.230316\n",
      "[50]\tvalid_0's binary_logloss: 0.380899\n",
      "[50]\tvalid_0's binary_logloss: 0.383793\n",
      "[50]\tvalid_0's binary_logloss: 0.382093\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.230122\n",
      "[50]\tvalid_0's binary_logloss: 0.381766\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.230324\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.230216\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.230347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=48)]: Done   5 out of   5 | elapsed: 20.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 1197.9786\n",
      "Function value obtained: 0.2262\n",
      "Current minimum: 0.2262\n",
      "Iteration No: 4 started. Evaluating function at random point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=48)]: Using backend LokyBackend with 48 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\tvalid_0's binary_logloss: 0.422741\n",
      "[25]\tvalid_0's binary_logloss: 0.42182\n",
      "[25]\tvalid_0's binary_logloss: 0.423756\n",
      "[25]\tvalid_0's binary_logloss: 0.422474\n",
      "[25]\tvalid_0's binary_logloss: 0.422442\n",
      "[50]\tvalid_0's binary_logloss: 0.513472\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.232187\n",
      "[50]\tvalid_0's binary_logloss: 0.512058\n",
      "[50]\tvalid_0's binary_logloss: 0.515138\n",
      "[50]\tvalid_0's binary_logloss: 0.513373\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.232024\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.23231\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.232144\n",
      "[50]\tvalid_0's binary_logloss: 0.513267\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.232225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=48)]: Done   5 out of   5 | elapsed:  9.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 539.2567\n",
      "Function value obtained: 0.2283\n",
      "Current minimum: 0.2262\n",
      "Iteration No: 5 started. Evaluating function at random point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=48)]: Using backend LokyBackend with 48 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\tvalid_0's binary_logloss: 0.370063\n",
      "[25]\tvalid_0's binary_logloss: 0.370172\n",
      "[25]\tvalid_0's binary_logloss: 0.36851\n",
      "[25]\tvalid_0's binary_logloss: 0.370503\n",
      "[25]\tvalid_0's binary_logloss: 0.36943\n",
      "[50]\tvalid_0's binary_logloss: 0.439265\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.230727\n",
      "[50]\tvalid_0's binary_logloss: 0.439213\n",
      "[50]\tvalid_0's binary_logloss: 0.440416\n",
      "[50]\tvalid_0's binary_logloss: 0.438807\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.230804\n",
      "[50]\tvalid_0's binary_logloss: 0.437469\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.230746\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.230581\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.230532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=48)]: Done   5 out of   5 | elapsed: 14.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 891.1050\n",
      "Function value obtained: 0.2266\n",
      "Current minimum: 0.2262\n",
      "Iteration No: 6 started. Evaluating function at random point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=48)]: Using backend LokyBackend with 48 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\tvalid_0's binary_logloss: 0.387682\n",
      "[25]\tvalid_0's binary_logloss: 0.388881\n",
      "[25]\tvalid_0's binary_logloss: 0.387428\n",
      "[25]\tvalid_0's binary_logloss: 0.3882\n",
      "[25]\tvalid_0's binary_logloss: 0.388608\n",
      "[50]\tvalid_0's binary_logloss: 0.464849\n",
      "[50]\tvalid_0's binary_logloss: 0.465366\n",
      "[50]\tvalid_0's binary_logloss: 0.466844\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.231271\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.231392\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.231449\n",
      "[50]\tvalid_0's binary_logloss: 0.466748\n",
      "[50]\tvalid_0's binary_logloss: 0.467021\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.231647\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.231407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=48)]: Done   5 out of   5 | elapsed: 12.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 6 ended. Evaluation done at random point.\n",
      "Time taken: 734.9580\n",
      "Function value obtained: 0.2274\n",
      "Current minimum: 0.2262\n",
      "Iteration No: 7 started. Evaluating function at random point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=48)]: Using backend LokyBackend with 48 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\tvalid_0's binary_logloss: 0.331841\n",
      "[25]\tvalid_0's binary_logloss: 0.331642\n",
      "[25]\tvalid_0's binary_logloss: 0.330739\n",
      "[25]\tvalid_0's binary_logloss: 0.331581\n",
      "[25]\tvalid_0's binary_logloss: 0.332044\n",
      "[50]\tvalid_0's binary_logloss: 0.384661\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.23062\n",
      "[50]\tvalid_0's binary_logloss: 0.384258\n",
      "[50]\tvalid_0's binary_logloss: 0.384553\n",
      "[50]\tvalid_0's binary_logloss: 0.383314\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.230585\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.230416\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.230356\n",
      "[50]\tvalid_0's binary_logloss: 0.385104\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.230476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=48)]: Done   5 out of   5 | elapsed: 15.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 7 ended. Evaluation done at random point.\n",
      "Time taken: 952.3342\n",
      "Function value obtained: 0.2264\n",
      "Current minimum: 0.2262\n",
      "Iteration No: 8 started. Evaluating function at random point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=48)]: Using backend LokyBackend with 48 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\tvalid_0's binary_logloss: 0.462096\n",
      "[25]\tvalid_0's binary_logloss: 0.463246\n",
      "[25]\tvalid_0's binary_logloss: 0.462455\n",
      "[25]\tvalid_0's binary_logloss: 0.462015\n",
      "[25]\tvalid_0's binary_logloss: 0.460447\n",
      "[50]\tvalid_0's binary_logloss: 0.573793\n",
      "[50]\tvalid_0's binary_logloss: 0.57408\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.233132\n",
      "[50]\tvalid_0's binary_logloss: 0.575457\n",
      "[50]\tvalid_0's binary_logloss: 0.573763\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.233412\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.233156\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.233326\n",
      "[50]\tvalid_0's binary_logloss: 0.570887\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.233208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=48)]: Done   5 out of   5 | elapsed:  7.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 8 ended. Evaluation done at random point.\n",
      "Time taken: 462.5295\n",
      "Function value obtained: 0.2293\n",
      "Current minimum: 0.2262\n",
      "Iteration No: 9 started. Evaluating function at random point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=48)]: Using backend LokyBackend with 48 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\tvalid_0's binary_logloss: 0.448854\n",
      "[25]\tvalid_0's binary_logloss: 0.446111\n",
      "[25]\tvalid_0's binary_logloss: 0.445954\n",
      "[25]\tvalid_0's binary_logloss: 0.446345\n",
      "[25]\tvalid_0's binary_logloss: 0.445132\n",
      "[50]\tvalid_0's binary_logloss: 0.553558\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.233502\n",
      "[50]\tvalid_0's binary_logloss: 0.550155\n",
      "[50]\tvalid_0's binary_logloss: 0.551359\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.232976\n",
      "[50]\tvalid_0's binary_logloss: 0.549963\n",
      "[50]\tvalid_0's binary_logloss: 0.548359\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.233236\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.232951\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.233141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=48)]: Done   5 out of   5 | elapsed: 29.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 9 ended. Evaluation done at random point.\n",
      "Time taken: 1754.2332\n",
      "Function value obtained: 0.2294\n",
      "Current minimum: 0.2262\n",
      "Iteration No: 10 started. Evaluating function at random point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=48)]: Using backend LokyBackend with 48 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\tvalid_0's binary_logloss: 0.357491\n",
      "[25]\tvalid_0's binary_logloss: 0.359046\n",
      "[25]\tvalid_0's binary_logloss: 0.359074\n",
      "[25]\tvalid_0's binary_logloss: 0.358114\n",
      "[25]\tvalid_0's binary_logloss: 0.359312\n",
      "[50]\tvalid_0's binary_logloss: 0.420042\n",
      "[50]\tvalid_0's binary_logloss: 0.421818\n",
      "[50]\tvalid_0's binary_logloss: 0.420852\n",
      "[50]\tvalid_0's binary_logloss: 0.421562\n",
      "[50]\tvalid_0's binary_logloss: 0.4221\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.231405\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.231479\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.23172\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.23152\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.23168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=48)]: Done   5 out of   5 | elapsed: 41.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 10 ended. Evaluation done at random point.\n",
      "Time taken: 2513.4114\n",
      "Function value obtained: 0.2275\n",
      "Current minimum: 0.2262\n",
      "Iteration No: 11 started. Evaluating function at random point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=48)]: Using backend LokyBackend with 48 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\tvalid_0's binary_logloss: 0.347846\n",
      "[25]\tvalid_0's binary_logloss: 0.348162\n",
      "[25]\tvalid_0's binary_logloss: 0.348619\n",
      "[25]\tvalid_0's binary_logloss: 0.346886\n",
      "[25]\tvalid_0's binary_logloss: 0.34706\n",
      "[50]\tvalid_0's binary_logloss: 0.406905\n",
      "[50]\tvalid_0's binary_logloss: 0.407949\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.230997\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.230944\n",
      "[50]\tvalid_0's binary_logloss: 0.408334\n",
      "[50]\tvalid_0's binary_logloss: 0.406526\n",
      "[50]\tvalid_0's binary_logloss: 0.405816\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.230953\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.230654\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.230682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=48)]: Done   5 out of   5 | elapsed: 16.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 11 ended. Evaluation done at random point.\n",
      "Time taken: 989.4646\n",
      "Function value obtained: 0.2267\n",
      "Current minimum: 0.2262\n",
      "Iteration No: 12 started. Evaluating function at random point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=48)]: Using backend LokyBackend with 48 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_86103/682478652.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         DeltaYStopper(\n\u001b[1;32m     10\u001b[0m             \u001b[0mdelta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0005\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mn_best\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             ),\n\u001b[1;32m     13\u001b[0m         ]\n",
      "\u001b[0;32m~/ian.castillo_nfs/my-kaggle-tools/competitions/tabular-playground-series-oct-2022/.kaggle-main/lib/python3.7/site-packages/skopt/optimizer/gp.py\u001b[0m in \u001b[0;36mgp_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs, model_queue_size)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mn_restarts_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_restarts_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mx0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         callback=callback, n_jobs=n_jobs, model_queue_size=model_queue_size)\n\u001b[0m",
      "\u001b[0;32m~/ian.castillo_nfs/my-kaggle-tools/competitions/tabular-playground-series-oct-2022/.kaggle-main/lib/python3.7/site-packages/skopt/optimizer/base.py\u001b[0m in \u001b[0;36mbase_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs, model_queue_size)\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_calls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0mnext_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m         \u001b[0mnext_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ian.castillo_nfs/my-kaggle-tools/competitions/tabular-playground-series-oct-2022/.kaggle-main/lib/python3.7/site-packages/skopt/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0;31m# Call the wrapped objective function with the named arguments.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mobjective_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0marg_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobjective_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_86103/4036312011.py\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(**params)\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \"callbacks\": [\n\u001b[1;32m     82\u001b[0m                     \u001b[0mearly_stopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                     \u001b[0mlog_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperiod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_stdv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# the rule of thumb is to have it at 10% of your num_estimators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m                     ],\n\u001b[1;32m     85\u001b[0m             }\n",
      "\u001b[0;32m~/ian.castillo_nfs/my-kaggle-tools/competitions/tabular-playground-series-oct-2022/.kaggle-main/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m         \u001b[0merror_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m     )\n\u001b[1;32m    522\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test_score\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ian.castillo_nfs/my-kaggle-tools/competitions/tabular-playground-series-oct-2022/.kaggle-main/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0merror_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         )\n\u001b[0;32m--> 283\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m     )\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ian.castillo_nfs/my-kaggle-tools/competitions/tabular-playground-series-oct-2022/.kaggle-main/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ian.castillo_nfs/my-kaggle-tools/competitions/tabular-playground-series-oct-2022/.kaggle-main/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    976\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ian.castillo_nfs/my-kaggle-tools/competitions/tabular-playground-series-oct-2022/.kaggle-main/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    565\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    566\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "reg_gp = gp_minimize(\n",
    "    objective, space,\n",
    "    verbose=1, \n",
    "    n_jobs=cpu_count(),\n",
    "    random_state=777, n_calls=50,\n",
    "    n_initial_points=15, \n",
    "    callback=[\n",
    "        # CheckpointSaver(\"../models/optmization/checkpoints/lgbm.pkl\", compress=9),\n",
    "        DeltaYStopper(\n",
    "            delta=0.0005,\n",
    "            n_best=5,\n",
    "            ),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('best score: {}'.format(reg_gp.fun))\n",
    "print('best params:')\n",
    "for i, param in enumerate(space):\n",
    "    print(f\"{param.name}: {reg_gp.x[i]} from space: [{param.low}, {param.high}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team = base_model.config[\"model\"][\"team\"]\n",
    "model = base_model.config[\"model\"][\"type\"]\n",
    "\n",
    "best_model_params = dict()\n",
    "for i, param in enumerate(space):\n",
    "    best_model_params[f\"{param.name}\"] = reg_gp.x[i]\n",
    "\n",
    "best_model_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train with All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from json import load\n",
    "# with open(f\"../models/team{team}/{model}_ipca_10perc/{model}_ipca_10perc.json\", \"r\") as f:\n",
    "#     best_model_params = load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = BaseModel()\n",
    "base_model.read_config(\"../models/config.yaml\")\n",
    "features, target = base_model.get_data()\n",
    "base_model.build_base_pipeline()\n",
    "\n",
    "if base_model.config[\"model\"][\"type\"] == \"xgb\":\n",
    "    best_model = XGBClassifier(**best_model_params, random_state=777)\n",
    "elif base_model.config[\"model\"][\"type\"] == \"lgbm\":\n",
    "    best_model = LGBMClassifier(**best_model_params, min_child_samples=None, random_state=777)\n",
    "\n",
    "base_model.base_pipeline.steps.append((\n",
    "    \"ipca\", \n",
    "    IncrementalPCA(\n",
    "        n_components=base_model.config[\"model\"][\"ipca\"][\"n_components\"], \n",
    "        batch_size=ipca_batch,\n",
    "        whiten=base_model.config[\"model\"][\"ipca\"][\"whiten\"]\n",
    "        ),\n",
    "    ))\n",
    "\n",
    "X_test_trans = base_model.base_pipeline.fit_transform(X_test)\n",
    "\n",
    "base_model.base_pipeline.steps.append((base_model.config[\"model\"][\"type\"], best_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_params = {\n",
    "    f\"{model}__eval_set\": [(X_test_trans, y_test)],\n",
    "    f\"{model}__eval_metric\": \"neg_log_loss\",\n",
    "    f\"{model}__callbacks\": [\n",
    "        early_stopping(100),\n",
    "        log_evaluation(period=50, show_stdv=True), \n",
    "    ],\n",
    "}\n",
    "\n",
    "fit_params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if base_model.config[\"model\"][\"type\"] == \"xgb\":\n",
    "    best_model = base_model.base_pipeline.fit(X_train_cv, y_train_cv)\n",
    "\n",
    "elif base_model.config[\"model\"][\"type\"] == \"lgbm\":\n",
    "    best_model = base_model.base_pipeline.fit(\n",
    "        X=X_train_cv, y=y_train_cv, **fit_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team = base_model.config[\"model\"][\"team\"]\n",
    "model = base_model.config[\"model\"][\"type\"]\n",
    "\n",
    "from joblib import dump\n",
    "dump(best_model, f\"../models/team{team}/{model}_ipca_10perc/{model}_ipca_10perc.joblib\")\n",
    "\n",
    "from json import dump, dumps\n",
    "with open(f\"../models/team{team}/{model}_ipca_10perc/{model}_ipca_10perc.json\", \"w\") as f:\n",
    "    dump(dumps(best_model_params, default=str), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = best_model.predict_proba(X_valid)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "log_loss(y_valid, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from pandas.core.frame import DataFrame, Series\n",
    "from pandas import concat\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "# Kudos to: Mateus Coelho\n",
    "# https://www.kaggle.com/code/mateuscco/how-to-evaluate-model-calibration/notebook\n",
    "\n",
    "def ece(y_test, preds, strategy = 'uniform'):\n",
    "    df = DataFrame({'target': y_test, 'proba': preds, 'bin': np.nan})\n",
    "    \n",
    "    if(strategy == 'uniform'):\n",
    "        lim_inf = np.linspace(0, 0.9, 10)\n",
    "        for idx, lim in enumerate(lim_inf):\n",
    "            df.loc[df['proba'] >= lim, 'bin'] = idx\n",
    "\n",
    "    elif(strategy == 'quantile'):\n",
    "        pass\n",
    "    \n",
    "    df_bin_groups = concat([df.groupby('bin').mean(), df['bin'].value_counts()], axis = 1)\n",
    "    df_bin_groups['ece'] = (df_bin_groups['target'] - df_bin_groups['proba']).abs() * (df_bin_groups['bin'] / df.shape[0])\n",
    "    return df_bin_groups['ece'].sum()\n",
    "\n",
    "def make_report(y_test, preds):\n",
    "    # Computing AUC\n",
    "    auc = roc_auc_score(y_test, preds)\n",
    "    display(f'AUROC: {auc}')\n",
    "    display(f'AUROC: {2*auc-1}')\n",
    "    display(f'Fraction of positive cases in the test set: {y_test.mean()}')\n",
    "    display(f'Mean predicted value in the test set:       {preds.mean()}')\n",
    "    display(f'ECE (equal width bins):       {ece(y_test, preds)}')\n",
    "    \n",
    "    # Plotting probabilities\n",
    "    display('#### Histogram of the probability distribution')\n",
    "    Series(preds).hist(bins = 40)\n",
    "    plt.show()\n",
    "    \n",
    "    # Plotting KDE by class\n",
    "    display('#### KDE plots of the probability distribution by class')\n",
    "    fig, ax1 = plt.subplots()\n",
    "    sns.kdeplot(preds[y_test == 0], label = 'No goal', ax = ax1)\n",
    "    ax2 = ax1.twinx()\n",
    "    sns.kdeplot(preds[y_test == 1], label = 'Goal within 10s', color = 'red', ax = ax2)\n",
    "    lines, labels = ax1.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    ax2.legend(lines + lines2, labels + labels2, loc=0)\n",
    "    plt.show()\n",
    "    \n",
    "    # Plotting calibration\n",
    "    display('#### Calibration curve (equal width bins)')\n",
    "    fop, mpv = calibration_curve(y_test, preds, n_bins=10)\n",
    "    plt.plot(mpv, fop, \"s-\", label='model')\n",
    "    plt.plot([0,0.25],[0,0.25], label='ideal')\n",
    "    plt.xlabel('Mean predicted value')\n",
    "    plt.ylabel('Fraction of positives')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    display('#### Calibration curve (equal size bins)')\n",
    "    fop, mpv = calibration_curve(y_test, preds, n_bins=10, strategy='quantile')\n",
    "    plt.plot(mpv, fop, \"s-\", label='model')\n",
    "    plt.plot([0,0.25],[0,0.25], label='ideal')\n",
    "    plt.xlabel('Mean predicted value')\n",
    "    plt.ylabel('Fraction of positives')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_report(y_valid, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.4 ('.kaggle-main': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e5c0cff39fa72bd2c44889eae792c2a5fab03a1c30a13a1587ff99bf2992359e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
